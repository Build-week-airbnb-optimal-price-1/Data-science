{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in /home/guillermo/anaconda3/lib/python3.7/site-packages (0.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_profiling\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/08/1f614fb2d31b59cd69896b900044c8d7119389b9151983a872d047ea021f/pandas-profiling-2.4.0.tar.gz (150kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 2.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pandas_profiling) (0.25.1)\n",
      "Requirement already satisfied: matplotlib>=1.4 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pandas_profiling) (3.1.1)\n",
      "Collecting confuse>=1.0.0 (from pandas_profiling)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
      "Requirement already satisfied: jinja2>=2.8 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pandas_profiling) (2.10.3)\n",
      "Collecting htmlmin>=0.1.12 (from pandas_profiling)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
      "Collecting missingno>=0.4.2 (from pandas_profiling)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/de/6e4dd6d720c49939544352155dc06a08c9f7e4271aa631a559dfbeaaf9d4/missingno-0.4.2-py3-none-any.whl\n",
      "Collecting phik>=0.9.8 (from pandas_profiling)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
      "\u001b[K     |████████████████████████████████| 614kB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astropy in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pandas_profiling) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pandas>=0.19->pandas_profiling) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pandas>=0.19->pandas_profiling) (1.17.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pandas>=0.19->pandas_profiling) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4->pandas_profiling) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4->pandas_profiling) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4->pandas_profiling) (2.4.2)\n",
      "Requirement already satisfied: pyyaml in /home/guillermo/anaconda3/lib/python3.7/site-packages (from confuse>=1.0.0->pandas_profiling) (5.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from jinja2>=2.8->pandas_profiling) (1.1.1)\n",
      "Requirement already satisfied: scipy in /home/guillermo/anaconda3/lib/python3.7/site-packages (from missingno>=0.4.2->pandas_profiling) (1.3.1)\n",
      "Requirement already satisfied: seaborn in /home/guillermo/anaconda3/lib/python3.7/site-packages (from missingno>=0.4.2->pandas_profiling) (0.9.0)\n",
      "Collecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas_profiling)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
      "Requirement already satisfied: numba>=0.38.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from phik>=0.9.8->pandas_profiling) (0.45.1)\n",
      "Requirement already satisfied: pytest>=4.0.2 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from phik>=0.9.8->pandas_profiling) (5.2.1)\n",
      "Requirement already satisfied: jupyter-client>=5.2.3 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from phik>=0.9.8->pandas_profiling) (5.3.3)\n",
      "Requirement already satisfied: nbconvert>=5.3.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from phik>=0.9.8->pandas_profiling) (5.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.19->pandas_profiling) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/guillermo/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas_profiling) (41.4.0)\n",
      "Requirement already satisfied: pylint>=1.4.5 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas_profiling) (2.4.2)\n",
      "Requirement already satisfied: llvmlite>=0.29.0dev0 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from numba>=0.38.1->phik>=0.9.8->pandas_profiling) (0.29.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (1.8.0)\n",
      "Requirement already satisfied: packaging in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (19.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (0.23)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas_profiling) (18.1.0)\n",
      "Requirement already satisfied: jupyter-core in /home/guillermo/anaconda3/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas_profiling) (4.5.0)\n",
      "Requirement already satisfied: tornado>=4.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas_profiling) (6.0.3)\n",
      "Requirement already satisfied: traitlets in /home/guillermo/anaconda3/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas_profiling) (4.3.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (0.3)\n",
      "Requirement already satisfied: defusedxml in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (0.6.0)\n",
      "Requirement already satisfied: testpath in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (0.4.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (0.8.4)\n",
      "Requirement already satisfied: pygments in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (2.4.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (4.4.0)\n",
      "Requirement already satisfied: bleach in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (3.1.0)\n",
      "Requirement already satisfied: isort<5,>=4.2.5 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas_profiling) (4.3.21)\n",
      "Requirement already satisfied: mccabe<0.7,>=0.6 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas_profiling) (0.6.1)\n",
      "Requirement already satisfied: astroid<2.4,>=2.3.0 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas_profiling) (2.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=4.0.2->phik>=0.9.8->pandas_profiling) (0.6.0)\n",
      "Requirement already satisfied: decorator in /home/guillermo/anaconda3/lib/python3.7/site-packages (from traitlets->jupyter-client>=5.2.3->phik>=0.9.8->pandas_profiling) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/guillermo/anaconda3/lib/python3.7/site-packages (from traitlets->jupyter-client>=5.2.3->phik>=0.9.8->pandas_profiling) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (3.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webencodings in /home/guillermo/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (0.5.1)\n",
      "Requirement already satisfied: lazy-object-proxy==1.4.* in /home/guillermo/anaconda3/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas_profiling) (1.4.2)\n",
      "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas_profiling)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/56/dd4e168a0009da85c78c6cfe91f5b2df2c7bbed60f3ba778c4a71289e6fb/typed_ast-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (736kB)\n",
      "\u001b[K     |████████████████████████████████| 737kB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt==1.11.* in /home/guillermo/anaconda3/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas_profiling) (1.11.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/guillermo/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas_profiling) (0.15.4)\n",
      "Building wheels for collected packages: pandas-profiling, confuse, htmlmin\n",
      "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandas-profiling: filename=pandas_profiling-2.4.0-py2.py3-none-any.whl size=195587 sha256=b65da464fea83dc78ebd78ab610d35f313cd4bb63ba1f4e0dc92ca2436e079c8\n",
      "  Stored in directory: /home/guillermo/snap/code/common/.cache/pip/wheels/b2/4b/40/ff4633a59f4e7fbdfec19b8e10e353b54b5eef125c31afe51a\n",
      "  Building wheel for confuse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for confuse: filename=confuse-1.0.0-cp37-none-any.whl size=17486 sha256=3f04d8c902f480b4cbfb6f77945a7f9a9d8c0b71930ca502f5d9c2eb52c0bc42\n",
      "  Stored in directory: /home/guillermo/snap/code/common/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp37-none-any.whl size=27086 sha256=96c9e977377b9ac277e63f2c3c586cc38e888b8d812312da2f4d9ab59d389d3c\n",
      "  Stored in directory: /home/guillermo/snap/code/common/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
      "Successfully built pandas-profiling confuse htmlmin\n",
      "Installing collected packages: confuse, htmlmin, missingno, pytest-pylint, phik, pandas-profiling, typed-ast\n",
      "Successfully installed confuse-1.0.0 htmlmin-0.1.12 missingno-0.4.2 pandas-profiling-2.4.0 phik-0.9.8 pytest-pylint-0.14.1 typed-ast-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'listings_tokyo.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-eb4b15bccd42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokyo_NLP\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/repos/Data-science/tokyo_NLP.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \"outputs\": [\n\u001b[1;32m      8\u001b[0m     {\n",
      "\u001b[0;32m~/Documents/repos/Data-science/Tokyo_deploy.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \"outputs\": [\n\u001b[1;32m      8\u001b[0m     {\n\u001b[0;32m----> 9\u001b[0;31m      \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"stderr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m      \u001b[0;34m\"output_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m      \"text\": [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'listings_tokyo.csv.gz'"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.tokyo_NLP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c763e17583ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistings_clean_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(listings_clean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col = ['accommodates','bathrooms',\n",
    "                 'cleaning_fee',\n",
    "                'minimum_nights','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_col].hist(figsize=(10,11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transforming columns because some features are highly skewed. \n",
    "numerical_col = [i for i in numerical_col if i not in ['accommodates']] # Removing items not to be transformed\n",
    "\n",
    "for col in numerical_col:\n",
    "        df[col] = df[col].astype('float64').replace(0.0, 0.01) # Replacing 0s with 0.01\n",
    "        df[col] = np.log(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target\n",
    "y_price = df['price']\n",
    "X_price = df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_price = pd.DataFrame(scaler.fit_transform(X_price), columns=list(X_price.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(\n",
    "                                                           X_price, y_price, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train_price, y_train_price)\n",
    "training_preds_xgb_reg = xgb_reg.predict(X_train_price)\n",
    "val_preds_xgb_reg = xgb_reg.predict(X_test_price)\n",
    "\n",
    "print(\"\\nTraining MSE:\", round(mean_squared_error(y_train_price, training_preds_xgb_reg),3))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test_price, val_preds_xgb_reg),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining r2:\", round(r2_score(y_train_price, training_preds_xgb_reg),3))\n",
    "print(\"Validation r2:\", round(r2_score(y_test_price, val_preds_xgb_reg),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train_price.columns)\n",
    "ft_weights_xgb_reg.sort_values('weight', inplace=True)\n",
    "#ft_weights_xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop feature weights of 0 \n",
    "ft_weights_xgb_reg = ft_weights_xgb_reg[(ft_weights_xgb_reg != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,32))\n",
    "plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
    "plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.margins(y=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use availability_30 as Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Target\n",
    "# y_30 = df['availability_30']\n",
    "# X_30 = df.drop(['availability_30','availability_90'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_30 = pd.DataFrame(scaler.fit_transform(X_30), columns=list(X_30.columns))\n",
    "# X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X_30, y_30, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg.fit(X_train_30, y_train_30)\n",
    "# training_preds_xgb_reg = xgb_reg.predict(X_train_30)\n",
    "# val_preds_xgb_reg = xgb_reg.predict(X_test_30)\n",
    "\n",
    "# print(\"\\nTraining MSE:\", round(mean_squared_error(y_train_30, training_preds_xgb_reg),3))\n",
    "# print(\"Validation MSE:\", round(mean_squared_error(y_test_30, val_preds_xgb_reg),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train_30.columns)\n",
    "# ft_weights_xgb_reg.sort_values('weight', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop feature weights of 0 \n",
    "# ft_weights_xgb_reg = ft_weights_xgb_reg[(ft_weights_xgb_reg != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting feature importances\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8,30))\n",
    "# plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
    "# plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
    "# plt.xlabel(\"Feature importance\")\n",
    "# plt.margins(y=0.01)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability_30 has a bigger MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use availability_90 as the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Target\n",
    "# y_90 = df['availability_90']\n",
    "# X_90 = df.drop(['availability_30','availability_90'],axis=1)\n",
    "\n",
    "# X_90 = pd.DataFrame(scaler.fit_transform(X_90), columns=list(X_90.columns))\n",
    "# X_train_90, X_test_90, y_train_90, y_test_90 = train_test_split(X_90, y_90, test_size=0.2, random_state=42)\n",
    "\n",
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg.fit(X_train_90, y_train_90)\n",
    "# training_preds_xgb_reg = xgb_reg.predict(X_train_90)\n",
    "# val_preds_xgb_reg = xgb_reg.predict(X_test_90)\n",
    "\n",
    "# print(\"\\nTraining MSE:\", round(mean_squared_error(y_train_90, training_preds_xgb_reg),3))\n",
    "# print(\"Validation MSE:\", round(mean_squared_error(y_test_90, val_preds_xgb_reg),3))\n",
    "\n",
    "# ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train_90.columns)\n",
    "# ft_weights_xgb_reg.sort_values('weight', inplace=True)\n",
    "# # Drop feature weights of 0 \n",
    "# ft_weights_xgb_reg = ft_weights_xgb_reg[(ft_weights_xgb_reg != 0).all(1)]\n",
    "\n",
    "# # Plotting feature importances\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8,30))\n",
    "# plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
    "# plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
    "# plt.xlabel(\"Feature importance\")\n",
    "# plt.margins(y=0.01)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability_90 has a huge MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model without regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(\n",
    "                                                           X_price, y_price, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(128, input_shape=(X_train_price.shape[1],), activation='relu'))\n",
    "nn.add(layers.Dense(256, activation='relu'))\n",
    "nn.add(layers.Dense(256, activation='relu'))\n",
    "nn.add(layers.Dense(512, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling the model\n",
    "nn.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])\n",
    "\n",
    "# Model summary\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "nn_history = nn.fit(X_train_price,\n",
    "                  y_train_price,\n",
    "                  epochs=150,\n",
    "                  batch_size=256,\n",
    "                  validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_evaluation(model,X_train, X_test, y_train, y_test, skip_epochs=0,):\n",
    "    \"\"\"\n",
    "    For a given neural network model that has already been fit, prints for the train and tests sets the MSE and r squared\n",
    "    values, a line graph of the loss in each epoch, and a scatterplot of predicted vs. actual values with a line\n",
    "    representing where predicted = actual values. Optionally, a value for skip_epoch can be provided, which skips that\n",
    "    number of epochs in the line graph of losses (useful in cases where the loss in the first epoch is orders of magnitude\n",
    "    larger than subsequent epochs). Training and test sets can also optionally be specified.\n",
    "    \"\"\"\n",
    "\n",
    "    # MSE and r squared values\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_pred),4))\n",
    "    print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_pred),4))\n",
    "    print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_pred),4))\n",
    "    print(\"Validation r2:\", round(r2_score(y_test, y_test_pred),4))\n",
    "    \n",
    "    # Line graph of losses\n",
    "    model_results = model.history.history\n",
    "    plt.plot(list(range((skip_epochs+1),len(model_results['loss'])+1)), model_results['loss'][skip_epochs:], label='Train')\n",
    "    plt.plot(list(range((skip_epochs+1),len(model_results['val_loss'])+1)), model_results['val_loss'][skip_epochs:], label='Test', color='green')\n",
    "    plt.legend()\n",
    "    plt.title('Training and test loss at each epoch', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_evaluation(nn,X_train_price,X_test_price, y_train_price, y_test_price, skip_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model with regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "nn2 = models.Sequential()\n",
    "nn2.add(layers.Dense(128, input_shape=(X_train_price.shape[1],), kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling the model\n",
    "nn2.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])\n",
    "\n",
    "# Model summary\n",
    "print(nn2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "nn2_history = nn2.fit(X_train_price,\n",
    "                  y_train_price,\n",
    "                  epochs=150,\n",
    "                  batch_size=256,\n",
    "                  validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_evaluation(nn2,X_train_price,X_test_price, y_train_price, y_test_price, skip_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net with Kernal Regularizers is best performing with lowest MSE and higest R2 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Pickle the darn thing! 🥒\n",
    "model_name = '/Users/karthikmahendra/Desktop/AirBnB/ABB.pkl' # path to where you want the file\n",
    "pickle.dump(xgb_reg, open(model_name, 'wb')) # kitty = the name of your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = X_train_price.iloc[0]\n",
    "y_tst = y_train_price.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "result = loaded_model.score(X_tst, y_tst)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
